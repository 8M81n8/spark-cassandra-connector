/*
 * Copyright DataStax, Inc.
 *
 * Please see the included license file for details.
 */

plugins {
    id 'nebula.maven-publish' version '5.1.5'
    id 'nebula.javadoc-jar' version '4.9.1'
    id 'scala'
}

configurations {
    testCompile.extendsFrom compileOnly
    provided
    compile.extendsFrom provided
}

sourceSets {
    // enable joint compilation
    main {
        java.srcDirs = []
        scala {
            srcDirs += "src/main/java"
        }
    }
    test {
        java.srcDirs = []
        scala {
            srcDirs += "src/test/java"
            srcDirs += "src/it/java"
            srcDirs += "src/it/scala"
        }
        resources.srcDirs += "src/it/resources"
    }
}

dependencies {
    compile project(':dse-core')

    def commonExcludes = {
        exclude group: 'com.esotericsoftware.kryo', module: 'kryo'
        exclude group: 'com.fasterxml.jackson.core'
        exclude group: 'com.sun.jersey'
        exclude group: 'commons-io', module: 'commons-io'
        exclude group: 'commons-codec', module: 'commons-codec'
        exclude group: 'io.dropwizard.metrics'
        exclude group: 'io.netty'
        exclude group: 'log4j', module: 'log4j'
        exclude group: 'jline', module: 'jline'

        exclude group: 'net.java.dev.jets3t', module: 'jets3t'
        exclude group: 'net.java.dev.jna', module: 'jna'
        exclude group: 'org.apache.avro', module: 'avro-ipc'
        exclude group: 'org.apache.cassandra', module: 'cassandra-all'
        exclude group: 'org.apache.cassandra', module: 'cassandra-thrift'
        exclude group: 'org.apache.curator'
        exclude group: 'org.jboss.netty'
        exclude group: 'org.scala-lang'
        exclude group: 'org.scalacheck', module: "scalacheck_${scalaLibVersion}"
        exclude group: 'org.scalatest', module: "scalatest_${scalaLibVersion}"
        exclude group: 'org.slf4j'
        exclude group: 'org.xerial.snappy', module: 'snappy-java'

        exclude module: 'jackson-mapper-asl'
        exclude module: 'paranamer'
        exclude module: 'py4j'

        exclude group: 'org.bouncycastle', module: 'bcprov-jdk15on'
    }

    def hadoopExcludes = {
        exclude group: 'org.apache.hadoop'
    }

    def sparkExcludes = commonExcludes << hadoopExcludes

    compileOnly("org.scala-lang:scala-compiler:${scalaVersion}") { force = true }
    compile("org.scala-lang:scala-library:${scalaVersion}") { force = true }
    compile("org.scala-lang:scala-reflect:${scalaVersion}") { force = true }

    compile "com.datastax.dse:dse-java-driver-core:${cassandraDseJavaDriverVersion}"
    compile "com.datastax.dse:dse-java-driver-mapping:${cassandraDseJavaDriverVersion}"

    provided("org.apache.hadoop:hadoop-client:${hadoopVersion}", commonExcludes)

    compile "org.joda:joda-convert:${jodaConvertVersion}"
    compileOnly "joda-time:joda-time:${jodaTimeVersion}"

    compile("com.google.guava:guava:${guavaVersion}")
    compileOnly("com.thoughtworks.paranamer:paranamer:${paranamerVersion}")

    provided("com.datastax.spark:spark-core_${scalaLibVersion}:${sparkVersion}", sparkExcludes)
    provided("com.datastax.spark:spark-catalyst_${scalaLibVersion}:${sparkVersion}", sparkExcludes)
    provided("com.datastax.spark:spark-hive_${scalaLibVersion}:${sparkVersion}", sparkExcludes)
    provided("com.datastax.spark:spark-sql_${scalaLibVersion}:${sparkVersion}", sparkExcludes)
    provided("com.datastax.spark:spark-streaming_${scalaLibVersion}:${sparkVersion}", sparkExcludes)
    provided("com.datastax.spark:spark-unsafe_${scalaLibVersion}:${sparkVersion}", sparkExcludes)

    compile "org.bouncycastle:bcprov-jdk15on:${bouncyCastleVersion}"
    compileOnly "com.esotericsoftware:kryo:${kryoVersion}"
    compileOnly "com.typesafe:config:${typesafeConfigVersion}"

    compile ("commons-beanutils:commons-beanutils:${commonsBeanutilsVersion}") {
        exclude group: "commons-logging"
    }

    compileOnly "commons-codec:commons-codec:${commonsCodecVersion}"
    compileOnly "commons-configuration:commons-configuration:${commonsConfigurationVersion}"
    compileOnly "commons-io:commons-io:${commonsIoVersion}"

    compileOnly "org.eclipse.jetty.aggregate:jetty-all:${jettyVersion}"

    compileOnly "io.dropwizard.metrics:metrics-json:${codahaleMetricsVersion}"
    compileOnly "io.netty:netty-all:${nettyVersion}"

    compileOnly "org.scala-lang.modules:scala-parser-combinators_${scalaLibVersion}:${scalaParserCombinatorsVersion}"

    compileOnly("com.fasterxml.jackson.module:jackson-module-scala_${scalaLibVersion}:${fasterxmlJacksonVersion}") { force = true }

    compile "org.apache.solr:solr-solrj:${solrVersion}"

    testCompile(project(':dse-core'))
    testCompile(project(path: ':dse-core', configuration: 'testOutput'))

    testCompile(project(':dse-spark'))
    testCompile(project(path: ':dse-spark', configuration: 'testOutput'))

    testCompile(project(':dse-analytics-core'))
    testCompile(project(path: ':dse-analytics-core', configuration: 'testOutput'))

    testCompile "org.scalacheck:scalacheck_${scalaLibVersion}:${scalaCheckVersion}"
    testCompile "org.scalamock:scalamock-scalatest-support_${scalaLibVersion}:${scalaMockVersion}"

    testCompile(group: "com.datastax.spark", name: "spark-core_${scalaLibVersion}", version: "${sparkVersion}", classifier: 'tests', sparkExcludes)
    testCompile(group: "com.datastax.spark", name: "spark-streaming_${scalaLibVersion}", version: "${sparkVersion}", classifier: 'tests', sparkExcludes)
    testCompile("com.datastax.spark:spark-repl_${scalaLibVersion}:${sparkVersion}", sparkExcludes)

    testRuntime "log4j:log4j:${log4jVersion}"
    testRuntime "org.slf4j:jul-to-slf4j:${slf4jVersion}"
    testRuntime "org.json4s:json4s-jackson_2.11:${json4sJacksonVersion}"

}

compileTestScala {
    dependsOn ':test-support:jar'
    doFirst {
        scalaCompileOptions.additionalParameters = ["-Xplugin:${project(':test-support').jar.archivePath}".toString()]
    }
}

rootProject.test.tasks << test

/**
 *  This changes dependency scope to configuration name if the dependency is present in the configuration.
 *  Ex. Configuration "provided" contains dependency spark-core. Spark-core scope is going to be changed to "provided".
 */
def overrideScope(Node dependency, Configuration configuration) {
    def artifactId = dependency.artifactId.text()
    if (configuration.allDependencies.find { it.name == artifactId } != null) {
        dependency.scope*.value = configuration.getName()
    }
}

def shortenVersion(Node dependency) {
    dependency.version*.value = (dependency.version.text() =~ /(\d+\.\d+\.\d+(?:-\w+)?)/)[0][1]
}

publishing {
    publications {
        nebula(MavenPublication) {
            pom.withXml {
                Node node = asNode() as Node
                node.dependencies.dependency.each { d ->
                    Node dependency = d as Node
                    def artifactId = dependency.artifactId.text()
                    def groupId = dependency.groupId.text()

                    overrideScope(dependency, project.configurations.getByName("provided"))
                    /**
                     *  Connector depends on internal version of netty, we need to migrate to public
                     *  [major.minor.path.Final] version
                     */
                    if (artifactId == "netty-all") {
                        shortenVersion(dependency)
                        dependency.version*.value = dependency.version.text() + ".Final"
                    }
                    /**
                     *  Move to OS version of spark
                     */
                    if (artifactId.startsWith("spark-") && groupId == "com.datastax.spark") {
                        dependency.groupId*.value = "org.apache.spark"
                        shortenVersion(dependency)
                    }
                }
            }
        }
    }
}
